{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformations\n",
    "\n",
    "# load mturk dataset with numerical labels\n",
    "data_mturk = transformations.get_mturk_pivot('nlabel_worker')\n",
    "\n",
    "# load staff annotated dataset\n",
    "data_staff = pd.read_hdf('data/store_public.h5', 'annotations/staff').dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6c5ad",
   "metadata": {},
   "source": [
    "# Annotation Quality\n",
    "### Staff annotations (preliminary experiment)\n",
    "Computing Cohen's Kappa, a metric to use to compute the **interrater agreement** between two raters. We have exactly two raters in case of our staff annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b879be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# compute Cohen's Kappa using the cohen_kappa_score function from scikit-learn\n",
    "kappa = cohen_kappa_score(data_staff['nlabel_staff1'], data_staff['nlabel_staff2'])\n",
    "\n",
    "print(f\"Cohen's Kappa {kappa}\")\n",
    "\n",
    "print(f\"Pairs with agreement {len(data_staff[data_staff.nlabel_staff1 == data_staff.nlabel_staff2])/len(data_staff)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75620ae3",
   "metadata": {},
   "source": [
    "### MTurk\n",
    "Since we have up to five raters in the case of MTurk, we have to apply different metrics. We compute **Krippendorff's Alpha**, since it is a robust measure in this case (multiple raters, considering random chance, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def krippendorff_pivot(df_hit_pivot: pd.DataFrame):\n",
    "    !pip install krippendorff\n",
    "    import krippendorff\n",
    "    try:\n",
    "        return round(krippendorff.alpha(df_hit_pivot.T, level_of_measurement='ordinal'), 2)\n",
    "    except AssertionError:\n",
    "        return None\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "krippendorff_pivot(data_mturk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab22610b",
   "metadata": {},
   "source": [
    "# Insights\n",
    "\n",
    "### Heatmap of uncertainty sample groups versus annotated labels\n",
    "Given our uncertainty sampling groups, we plot the relationship with those to the annotated labels by majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# font size to 16\n",
    "#plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# filter data to plot\n",
    "plot_data = transformations.get_annotations().query('origin != \"staff\"').reset_index().pivot_table(\n",
    "    index='label', columns='sample_group', aggfunc='size').rename({'ditto_favs': 'Metadata\\nFavored',\n",
    "                                                                            'mutual_unconfident': 'Mutual\\nUncertain',\n",
    "                                                                            're-move_favs': 'Audio\\nFavored'}, axis=1\n",
    ")\n",
    "\n",
    "def heatmap_annotations(df):\n",
    "    \n",
    "    def get_key(x):\n",
    "        if x == \"Metadata-Favored\":\n",
    "            return \"ditto_favs\"\n",
    "        elif x == \"Mutual Uncertain\":\n",
    "            return \"mutual_unconfident\"\n",
    "        elif x == \"Audio-Favored\":\n",
    "            return \"re-move_favs\"\n",
    "           \n",
    "    for rowIndex, row in plot_data.iterrows(): #iterate over rows\n",
    "        for columnIndex, value in plot_data.items():\n",
    "            try:\n",
    "                tertiary_value = ' (' + str(int(tertiary.loc[(get_key(columnIndex), rowIndex), 'set_id'])) + ')'\n",
    "            except KeyError:\n",
    "                tertiary_value = ' (0)'\n",
    "            try:\n",
    "                df.loc[rowIndex, columnIndex] = str(int(df.loc[rowIndex, columnIndex])) + tertiary_value\n",
    "            except ValueError:\n",
    "                df.loc[rowIndex, columnIndex] = None\n",
    "    return df\n",
    "\n",
    "\n",
    "# custom sort\n",
    "label_type = pd.Categorical(plot_data.index, \n",
    "               categories=['Match', 'Version', 'Other', 'No Music', 'No Majority'], ordered=True)\n",
    "plot_data.index = label_type\n",
    "plot_data = plot_data.sort_index()\n",
    "\n",
    "# init heatmap and customize\n",
    "ax = sns.heatmap(plot_data, annot=True, fmt='.0f', cmap='YlGnBu')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42feb608",
   "metadata": {},
   "source": [
    "### Cue-based analysis\n",
    "We can analyze our dataset with regards to cues (eg. *cover*, *guitar*, *reaction*) indicating specific types of noise such as changes in structure (music and non-music). In the following, we show an example how this can be done.\n",
    "\n",
    "1. We load the cue dataframes from the store and consider an OR-relationship (cue has to be either in the title or description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70984811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading cues and attaching to the data\n",
    "title_cues = pd.read_hdf('data/store_public.h5', 'metadata/yt_title_cues')\n",
    "description_cues = pd.read_hdf('data/store_public.h5', 'metadata/yt_title_cues')\n",
    "cues = title_cues | description_cues\n",
    "cues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22478b4b",
   "metadata": {},
   "source": [
    "2. Now we map each YouTube ID to the cue existance. This returns more rows than videos, because one video can have multiple cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cues to cue type column\n",
    "data_cues = cues.stack().reset_index().rename(\n",
    "    {'yt_id': 'candidate_yt_id', 'level_1': 'Type Cue', 0: 'flag'}, axis=1)\n",
    "data_cues = data_cues.loc[data_cues.flag, ['candidate_yt_id', 'Type Cue']]\n",
    "data_cues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107c238",
   "metadata": {},
   "source": [
    "3. Now we do some further preprocessing (merging, limiting to top 20 most frequent cues). The result is our dataset merged with the cue information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816fa07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with dataset\n",
    "dataset_cues = pd.merge(transformations.get_dataset(), data_cues, how='left', on='candidate_yt_id')\n",
    "\n",
    "# record if a cue is among the top 20 most frequent cues\n",
    "dataset_cues[\"Type Cue Top\"] = dataset_cues[\"Type Cue\"].apply(\n",
    "    lambda x: x if x in dataset_cues[\"Type Cue\"].value_counts().head(20) else pd.NA\n",
    "                                                                 )\n",
    "# \n",
    "dataset_cues = pd.merge(dataset_cues, pd.read_hdf('data/store_public.h5', \n",
    "                                                  'metadata/version_cues').drop_duplicates(\n",
    "    subset='cue'), how='left', \n",
    "         left_on='Type Cue', right_on='cue', suffixes=['', '_cue'])\n",
    "\n",
    "dataset_cues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d188e08",
   "metadata": {},
   "source": [
    "4. Here we show how we manually aggregated cues to categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3351646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cue_category(x):\n",
    "    if x in [\"official\", \"cover\", \"lyrics\", \"live\"]:\n",
    "        return x\n",
    "    elif x in [\"guitar\", \"piano\", \"drum\"]:\n",
    "        return \"instruments: guitar, piano, drums\"\n",
    "    elif x in [\"instrumental\", \"karaoke\", \"vocal\"]:\n",
    "        return \"expected alterations in audio dimension\"\n",
    "    elif x in [\"tutorial\", \"reaction\", \"remix\"]:\n",
    "        return \"expected alterations in time dimension\"\n",
    "    elif x in [\"audio\", \"hd\"]:\n",
    "        return \"audio, hd\"\n",
    "    elif x in [\"version\", \"performance\"]:\n",
    "        return \"version, performance\"\n",
    "    else: \n",
    "        return x\n",
    "    \n",
    "dataset_cues[\"Cue Category\"] = dataset_cues[\"Type Cue\"].apply(get_cue_category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec51cb",
   "metadata": {},
   "source": [
    "5. Now, we plot based on these categories. Please note that plotting everything at once leads to too many overlaps of datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5175974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Define categories to filter by\n",
    "categories = [\"cover\", \"instruments: guitar, piano, drums\", \"expected alterations in audio dimension\", \n",
    "              \"expected alterations in time dimension\"]\n",
    "\n",
    "plt.tight_layout()\n",
    "# Create figure and axes objects\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8), sharex=True, sharey=True)\n",
    "\n",
    "color_palette = custom_palette = palette ={\"Match\": \"green\", \"Version\": \"blue\", \"Other\": \"orange\", \n",
    "                                           \"No Music\": \"red\"}\n",
    "\n",
    "\n",
    "# plotdata\n",
    "plotdata = dataset_cues.query('~label.isin([\"Uncertain\"])')\n",
    "plotdata = plotdata.rename({'label': 'Label'}, axis=1)\n",
    "\n",
    "# scatterplot for each category and subplot\n",
    "for i, category in enumerate(categories):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    filtered_data = plotdata[plotdata[\"Cue Category\"] == category].sort_values(by='Label')\n",
    "    if len(category.split(',')) > 1 or len(category.split(' ')) > 1:\n",
    "        sns.scatterplot(x=\"music_ratio\", y=\"re-move_pred\", hue=\"Label\", style=\"Type Cue\", \n",
    "                        data=filtered_data, ax=axes[row, col], alpha=0.5, palette=color_palette)\n",
    "    else:\n",
    "        sns.scatterplot(x=\"music_ratio\", y=\"re-move_pred\", hue=\"Label\", \n",
    "                data=filtered_data, ax=axes[row, col], alpha=0.5, palette=color_palette)\n",
    "    axes[row, col].set_title(category)\n",
    "    \n",
    "    axes[row, col].set_xlabel(\"YOHO Music Ratio\")\n",
    "    plt.xlim([-0.01,1.01])\n",
    "    axes[row, col].set_ylabel(\"Re-MOVE Prediction\")\n",
    "\n",
    "# legends \n",
    "handles, labels = axes[1, 1].get_legend_handles_labels()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
